[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to RED‚ÄëX",
    "section": "",
    "text": "2.0 Background and Motivation\nRED-X was developed in response to a growing need for efficient access to historical research datasets‚Äîparticularly in the agricultural and environmental sciences.\nOver the years, large volumes of valuable data have been collected by researchers at the University of Guelph, especially through the Ontario Agricultural College (OAC). However, much of this data remained siloed, inconsistently described, or difficult to navigate, making reuse a significant challenge.\nThe motivation behind RED-X came from a workshop hosted by the University of Guelph in collaboration with Compute Ontario, which focused on enhancing the FAIRness (Findability, Accessibility, Interoperability, and Reusability) of research data. Researchers, librarians, and data specialists at the event emphasized the need for a user-friendly tool that could help bridge the gap between stored data and actionable insight.\nRED-X was thus envisioned as a web-based metadata and dataset discovery platform, built using RShiny, that connects directly to Borealis, a Dataverse-based data repository platform. The app provides both technical and non-technical users with intuitive tools for exploring, visualizing, and filtering datasets, enabling better use of existing research outputs and supporting data-driven collaboration across departments and institutions.\n\n\n\n3.0 Purpose & Goals\n\nUnlock historical research insights ‚Äî aggregates metadata and datasets from multiple colleges and departments within the Agri-environmental Research Data dataverse in Borealis (Canadian Dataverse Repository).\nPromote FAIR principles ‚Äî ensures data is Findable, Accessible, Interoperable, and Reusable, elevating the value of Agri-Food data.\nEnhance discoverability ‚Äî presents keyword-author network visualizations and smart filters to reveal connections and trends.\n\n\n\n\n4.0 Who Should Use RED‚ÄëX\n\nAcademic researchers/Scientist investigating historical trends.\n\nData librarians and stewards aiming to manage and share historical datasets.\n\nGraduate students conducting meta-analyses or literature reviews/data review.\n\n\n\n\n5.0 Key Features in Version 2.0\n\nOptimized loading through direct database access and 48‚Äëhour auto-refresh.\n\nNetwork Explorer ‚Äî visualize relationships among keywords, authors, institutions, and colleges.\nExplore datasets and metadata- Navigate historical datasets collected across various colleges and departments, with metadata drawn directly from Borealis.\nSmart Filters ‚Äî quickly navigate by college, department, or campus.\n\nHome Tab Summary ‚Äî at-a-glance metrics for available studies and datasets.\nView study-level summaries - Gain insight into each dataset through high-level summary statistics, research objectives, study location, and associated keywords.\nSeamless navigation ‚Äî one-click access to Network or Data Explorer interfaces.\n\n\n\n\n6.0 Getting Started\nVisit the Getting Started to launch the RED‚ÄëX app, explore its structure, understand system requirements, and get a quick overview of how to navigate and begin using its core features.\n\n\n\n7.0 Browse the Documentation\nUse the sidebar to navigate in sequence:\n\nGetting Started\n\nUser Guide\n\nSystem Architecture\n\nAPI Guide\nDeveloper Guide\n\n\n\n\n8.0 Support & Credits\nRED‚ÄëX was developed by Agri‚ÄëFood Data Canada at the University of Guelph with support from the Canada First Research Excellence Fund. Special thanks to Dr.¬†Busayo Kodaolu for contributions to the design, development, and documentation of RED‚ÄëX Version 2.0. For inquiries or technical support, contact: adc@uoguelph.ca."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "contributing.html",
    "href": "contributing.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "getting-started.html",
    "href": "getting-started.html",
    "title": "Getting Started",
    "section": "",
    "text": "2.0 Accessing RED-X\nYou can access the app directly through the following link: üîó Launch RED-X\n\nNote : No installation or login is required. RED-X is optimized for desktop browsers. Mobile functionality is limited.\n\n\n\n\n3.0 System Requirements\n\nA modern web browser (Chrome, Firefox, Edge).\nStable internet connection.\nRecommended screen resolution: 1280√ó720 or higher.\n\n\n\n\n4.0 Overview of the Interface\nWhen you launch RED-X, you‚Äôll land on the Home tab, which provides an at-a-glance overview of the database contents. The layout includes a carousel-style summary displaying summary statistics like:\n\nConnected dataverses\nTotal number of studies\nNumber of authors\nAvailable keywords\nNumber of downloadable files\n\n\nIt also introduces users to the two primary interactive tools like:\n\n4.1 Network Explorer\nThis tab allows you to explore relationships between keywords, authors, departments, and colleges using an interactive network graph. It‚Äôs designed to support discovery, literature and data review, and collaboration tracking.\n\n\n\n4.2 Data Explorer\nThis section allows users to browse and filter studies, view their metadata, raw data, summary statistic and visualize data. Filters are available by college, campus and institution.\n\n\n\n\n\n5.0 Data Refresh Cycle\nRED-X connects to the Borealis Dataverse using an API calls. Metadata and datasets are updated every 48 hours to ensure access to the most recent content available from contributing institutions.\n\n\n\n\n6.0 Next Steps\n\nRead the User Guide for more detailed walkthroughs.\nView the System Architecture to understand the backend and data flow.\nContact adc@uoguelph.ca for questions or support.\n\n\n\n\n7.0 Want to Contribute?\nIf you‚Äôre interested in the development process or contributing to the project, see the Developer Guide."
  },
  {
    "objectID": "user-guide.html",
    "href": "user-guide.html",
    "title": "User Guide",
    "section": "",
    "text": "2.0 Home Tab\nWhen you first access RED-X, you‚Äôre welcomed by the Home tab, which serves as both an overview and introduction to the platform.\nAt the top of the page is a carousel-style summary that cycles through key statistics and features:\n\nAvailable dataverses\nTotal number of studies\nNumber of authors and keywords\nNumber of downloadable files\n\n\nFigure: Home tab displaying summary statistics.\nThe Home tab also includes a visual preview and description of the two main functional areas of the app:\n\nNetwork Explorer ‚Äì For visualizing data relationships by keyword, author, and institution.\nData Explorer ‚Äì For detailed study-level metadata browsing and file access.\n\nBeneath the carousel, you‚Äôll find a short introduction to the RED-X platform. This text outlines the purpose of the app ‚Äî helping users explore historical Agri-Food data, identify reusable datasets, and support various stages of research.\n\nTip: Use the Home tab as a launching point to understand what‚Äôs available and choose your next step based on your research needs.\n\n\n\n3.0 Network Explorer\nThe Network Explorer tab provides an interactive visualization of how studies are connected through shared keywords and authors, as well as their associated colleges and departments. This tool helps users uncover patterns, identify collaborators, and explore thematic clusters across historical datasets.\nUser can use the filters feature to narrow results, then interact with nodes in the network to see how keywords, people, and institutions are connected.\n\n\n3.1 Featured example:\nSuppose you are planning a research project focused on pH. Here‚Äôs how RED-X supports your workflow:\n\nSearch for the keyword (e.g., ‚ÄúpH‚Äù) to reveal all related studies, other linked keywords, and contributing authors.\n\n\n\nClick nodes to highlight related studies.\nHover over nodes to reveal labels and context.\n\n\n\nUse dropdown filters to focus the network by:\n\nCollege/Campus/Institution\nDepartment/Campus\n\nZoom, pan and scroll down to navigate the network space dynamically and display more details about the keywords including the number of associated studies and links to their DOIs on the Borealis Dataverse.\n\n\nThe visual structure enables discovery of new directions for research, potential collaborators, and dataset relevance based on shared keywords or institutional ties.\n\n\nFigure: Network Explorer showing the keyword ‚ÄúpH‚Äù with connections to related studies, authors, and academic departments.\n\nExplore Collaborations:\nTrace authors or departments with similar work and explore their datasets for deeper context. The legend displays the color assigned to each department, making it easier to visually trace connections within the network. The ‚ÄúShared Across Multiple‚Äù category represents keywords or authors that appear in more than one department or college.\n\n\n\nTip: Use this tool early in your research planning to map out what‚Äôs already been studied and where gaps or opportunities may exist.\n\n\n\n\n4.0 Data Explorer\nThe Data Explorer tab presents a comprehensive, filterable table of all available studies harvested from the Borealis Dataverse. It serves as the primary interface for browsing study-level metadata and accessing associated data files.\nUsers can:\n\nFilter by college, department, or dataverse using dynamic dropdowns.\nSearch by keyword to find studies relevant to specific topics (e.g., pH, manure, cover crops).\n\n\n\nView metadata including study title, publication date, authors, affiliated institution, and study objectives.\n\n\n\nAccess available files.\n\n\n4.1 Featured Example\nThis example walks you through interacting with an individual study using the Data Explorer tab. You can view metadata, inspect raw data files, and review summary statistics to evaluate the study‚Äôs content and reusability.\n\nStudy Overview\n\nThe Study Overview tab provides a concise, table-form summary of the metadata associated with a selected study. It displays key information such as the study title, period covered, DOI, data license, and other relevant details in a clear two-column layout. It also displays some interactive elements such as clickable DOI and license links to enhance usability and visibility. This tab offers users a quick and accessible way to assess study-level information before exploring raw data or associated files.\n\n\nView Metadata\n\nThe Metadata tab helps users explore important background information about each dataset. When available, it shows two sections: a Data Description, which gives general details about the study, and a Data Schema, which outlines the structure of the dataset (such as column names and types). RED-X automatically displays this information if a compatible .txt metadata file is included. However, if no metadata file is found or the file is in an unsupported format (like PDF or Word), the tab will show no metadata file found indicating that metadata is not available. This feature gives users a quick overview of a dataset‚Äôs context before reviewing the raw data.\n\nFigure showing what is displayed when metadata is available\n\n\nFigure showing what is displayed when metadata is not available\n\nData exploration Tab\n\nView All Datafile This section displays the full contents of the selected dataset in an interactive table. Users can scroll, search, and sort the data to explore the raw values directly within the app. It‚Äôs helpful for quickly reviewing the structure of the dataset, spotting missing values, or identifying specific entries.\n\nData Summary The Data Summary section provides basic descriptive statistics for numeric columns in the selected dataset. This includes metrics like mean, minimum, maximum, and counts. It gives users a quick snapshot of the data‚Äôs distribution and quality, helping to assess its potential for reuse. If the dataset contains only text or unsupported values, the summary may be blank or trigger an error message.\n\nNote: The Data Exploration tab only supports .tab or .csv file formats. If no compatible data file is found, or if the dataset is missing entirely, the app will display a message no data files found indicating that no data file is available. Additionally, the Data Summary and Data Visualization features are designed to work with numeric data. If the selected file contains only text or unsupported formats, these sections may show an error or return no results.\n\nData Visualization This section generates simple plots (e.g., histograms or scatter plots) based on the dataset‚Äôs contents. It allows users to visually explore trends, compare variables, and better understand the shape and relationships within the data. Visualizations are most useful when the dataset includes numeric columns. If the data is not suitable for plotting, this section may not display any output.\nSelect studies with accessible files for preliminary data review for reuse. Users can select datasets to view trends and summary statistics, helping them better understand the structure, scope, and potential reusability of historical data for their own research.\n\nFigure: Example of visualizing dataset trends and summary statistics using the data visualization tool within RED-X.\n\nTip: Use the Data Explorer to review metadata and visualize data. Reviewed studies and data can provide useful context or methodological references for prelimimary stage during project development.\n\n\n\n\n5.0 About Tab\nThe About tab contains background information on RED-X, its goals, and contributing institutions. This section is useful for understanding the development context and the broader research infrastructure it supports. It also gives information about the development team.\n\n\n\n6.0 Tips & Best Practices\n\nStart with broad searches to discover unexpected related studies.\nUse both the Network and Data Explorer tabs for a comprehensive view.\nUse the summary boxes in the Home tab to monitor total data availability.\nData updates every 48 hours ‚Äî revisit often for new studies.\n\n\n\n\n7.0 Need More Help?\nIf you need further assistance using the platform, refer to the Getting Started guide or contact the support team at adc@uoguelph.ca."
  },
  {
    "objectID": "user-guide.html#need-more-help",
    "href": "user-guide.html#need-more-help",
    "title": "User Guide",
    "section": "2 Need More Help?",
    "text": "2 Need More Help?\nIf you need further assistance using the platform, refer to the Getting Started guide or contact the support team at adc@uoguelph.ca."
  },
  {
    "objectID": "architecture.html",
    "href": "architecture.html",
    "title": "System Architecture",
    "section": "",
    "text": "2.0 Key components\nRED-X is composed of several key components that work together to deliver a smooth and responsive data exploration experience. Each part plays a specific role in fetching, preparing, and displaying data to users.\n\n\n\nComponent\nDescription\n\n\n\n\nFrontend (User Interface)\nBuilt with R Shiny, the frontend is modular and reactive. It includes:- Carousel-style home summary- Keyword/author network visualization- Data Explorer with filtering- Tooltip and sidebar interactivity- Dynamic filters, value boxes, tables, and visualizations- Hosted on shinyapps.io\n\n\nBackend (Data Engine)\n- Uses a lightweight SQLite database stored locally- Stores cleaned and structured metadata from the Borealis Dataverse- Includes tables for metadata, files, keywords, authors, and network edges- Optimized for fast queries and minimal setup\n\n\nAPI Integration\n- Connects to the Borealis Dataverse API- Retrieves metadata, file listings, DOIs, and keyword-author tags- Data is fetched as JSON and processed into tidy tabular format\n\n\nScheduled Update Process\n- Runs every 48 hours to refresh the database- Uses an automated R script to:¬†¬†¬†‚Ä¢ Pull updated metadata and files¬†¬†¬†‚Ä¢ Clean and transform the data¬†¬†¬†‚Ä¢ Merge into the SQLite database- Keeps the app in sync with Borealis\n\n\n\n\nNote: Some of these key features are explained in more detail in the sections that follow.\n\n\n\n3.0 Data Flow Pipeline\nThe data flow in RED-X follows a streamlined, automated process that ensures users always have access to the most up-to-date study metadata and data files.\nData originates from the Borealis Dataverse, where it is retrieved using API calls. Once fetched, the data is cleaned, transformed, and stored in a local SQLite database, which the app uses to deliver fast and filtered responses to users in real time.The diagram below summarizes the process. Each component plays a specific role in moving data through the system.\n\n\n3.1 Fetching Data from Borealis using API calls\n\n1. API Integration for data fetching\nRED-X connects to the Borealis Dataverse API to fetch metadata, datasets, and file information from public and restricted research repositories. This guide provides a high-level overview of how the API is integrated into the app.\nThe RED-X app integrates with the Borealis Dataverse API to automatically retrieve and update metadata, authorship information, keywords, DOIs, and associated research files. This integration allows RED-X to stay synchronized with the most recent dataset updates on Borealis, without requiring manual downloads or uploads. It streamlines the process of discovering and exploring historical research data.\nAPI calls are made using custom R functions that fetch and process the data into a clean, structured format. Access to the API is secured using a user-specific token stored in environment variables, ensuring both security and flexibility. Depending on user permissions (e.g., general user vs.¬†superuser), access levels to certain data may vary.\n\nNote: Detailed information about the API integrations and functions can be found at the API Guide section.\n\n\n\n2. Data cleaning, transformation\nAfter data is fetched from the Borealis Dataverse via API calls, it undergoes a structured pipeline that cleans, transforms, and stores the information in a lightweight SQLite database for fast retrieval and application use.\nThe raw metadata and file listings are parsed and cleaned using a combination of R packages like dplyr, tidyr, and stringr. Below are the main steps:\n\n\n\n\n\n\n\nStep\nDescription\n\n\n\n\nFlatten JSON Responses\nNested JSON responses from the API are converted into tabular format using jsonlite::fromJSON(..., flatten = TRUE).\n\n\nFilter Valid Datasets\nEntries are filtered to ensure they have a valid persistent_id (DOI) and required metadata.\n\n\nExtract and Normalize\nMetadata such as authors, keywords, temporal coverage, and spatial coverage are parsed and stored in a tidy format.\n\n\nString Cleanup\nFields like keywords and authors are cleaned to remove extraneous punctuation, whitespace, or formatting artifacts.\n\n\nDeduplication\nIdentical entries are removed to avoid redundancy using dplyr::distinct().\n\n\nFile Filtering\nOnly .tab, .csv, and metadata .txt files are retained. A helper function filter_filelist() ensures correct file extensions are selected.\n\n\n\n# Example: Clean a raw keyword string\ncleaned_keywords <- str_split(raw_keywords, \";\\\\s*\") %>%\n  unlist() %>%\n  str_replace_all(\"[^a-zA-Z0-9\\\\s-]\", \"\") %>%\n  str_squish() %>%\n  str_to_title() %>%\n  unique()\n\n\n3. Storage in SQLite Database\nOnce cleaned, the data is stored in an SQLite database bundled with the Shiny app. This makes querying and updating lightweight, portable, and fast.\n\n\n\n\n\n\n\nTable\nPurpose\n\n\n\n\nresearch_data\nStores the core metadata of all studies (DOI, title, authors, publication date, etc.)\n\n\nupdate_info\nKeeps a timestamp of the last update to prevent redundant API calls (refresh every 48 hours)\n\n\nkeywords_node/edge\nStores the network data for keyword co-occurrence\n\n\nauthors_node/edge\nStores the network data for author collaboration\n\n\ncollege_colors\nColor mapping for each college used in the network visualization\n\n\ndepartment_colors\nColor mapping for each department used in the network visualization\n\n\n\n# Example: Save cleaned study metadata to SQLite\ndbWriteTable(conn, \"research_data\", cleaned_metadata, append = TRUE)\n\nThe SQLite database is accessed by the Shiny app at runtime to populate the user interface with up-to-date and searchable content.\n\n\n\n4. Scheduled Updates\nA background R script checks if an update is needed (based on a 48-hour interval) and refreshes the database only when new datasets are detected. This ensures a responsive app while minimizing API load.\n # Check if update_info table exists and when it was last updated\n  if (\"update_info\" %in% dbListTables(conn)) {\n    update_info <- dbReadTable(conn, \"update_info\")\n    if (nrow(update_info) > 0) {\n      last_update <- as.POSIXct(update_info$last_update[1])\n      time_diff <- difftime(Sys.time(), last_update, units = \"hours\")\n      if (time_diff < 48) {\n        update_needed <- FALSE\n        message(\"Less than 48 hours since last update (\", round(time_diff, 2), \" hours). Using cached data.\")\n      }\n    }\n  }\n  \n  if (!update_needed && (\"research_data\" %in% dbListTables(conn))) {\n    # Return cached data if no update is needed\n    return(dbReadTable(conn, \"research_data\"))\n  }\n  \n  message(\"Updating cache with new data...\")\n\nThis automated pipeline ensures that users always see the most recent research metadata available in the Borealis repository.\n\n\n\n\n\n4.0 Deployment\nThe RED‚ÄëX application is currently deployed using shinyapps.io, a cloud-based hosting service for Shiny applications by RStudio (Posit). This enables the app to be publicly accessible from any browser without requiring local installation of R or its dependencies.\nThe RED-X App is publicly accessible via the following link: Launch RED-X on shinyapps.io\nThis app is actively version-controlled and maintained through GitHub. You can view the full source code, contribute, or report issues using the repository link below: View RED-X on GitHub\nThe GitHub repository contains: - All the source code (UI and server components) - Scripts for API integration and data processing - Deployment and update scripts - Project documentation and development history\n\nTip: For details on local development or contributing, see the Developer Guide section."
  },
  {
    "objectID": "architecture.html#overview",
    "href": "architecture.html#overview",
    "title": "System Architecture",
    "section": "1 Overview",
    "text": "1 Overview\nThe system architecture section provides a high-level overview of how RED-X is built and how its components interact to deliver a seamless user experience. It outlines the core technologies used, the data flow from external sources to the app interface, and how the system stays up-to-date through automated processes.\nThis section is intended for developers, technical reviewers, and advanced users who want to understand how RED-X integrates data from the Borealis Dataverse, processes it for analysis, and presents it through an interactive Shiny interface.\nRED-X is a browser-based web application developed using R Shiny and hosted on shinyapps.io. It connects to a local relational database (SQLite) that is updated every 48 hours via an API integration with the Borealis Dataverse. The system is optimized for metadata visualization, interactive filtering, and reusability analysis."
  },
  {
    "objectID": "architecture.html#system-architecture-diagram",
    "href": "architecture.html#system-architecture-diagram",
    "title": "System Architecture",
    "section": "2 System Architecture Diagram",
    "text": "2 System Architecture Diagram\n\nüì∑ Insert a flow diagram or ERD here\nExample:\n![](images/system-architecture.png){width=80%}"
  },
  {
    "objectID": "architecture.html#key-components",
    "href": "architecture.html#key-components",
    "title": "System Architecture",
    "section": "3 üß© Key Components",
    "text": "3 üß© Key Components\n\n3.1 üîπ Frontend (User Interface)\nBuilt with Shiny, the frontend is modular and reactive. It provides:\n\nCarousel-style home summary\nKeyword/author network visualization\nData Explorer table with filtering\nTooltip and sidebar interactivity\n\n\n\n3.2 üîπ Backend (Data Engine)\n\nSQLite used as the local on-disk relational database\nStores:\n\nStudy metadata\nAuthor/keyword relationships\nNetwork node and edge tables\n\nAll data is auto-refreshed every 48 hours\n\n\n\n3.3 üîπ API Integration\nRED-X uses the Dataverse API to fetch: - Study-level metadata - File listings - Author and keyword tags - DOIs and study-level links\nA scheduled R script (e.g., via cron or shinyapps.io scheduler) handles this process and repopulates the SQLite database."
  },
  {
    "objectID": "architecture.html#data-flow",
    "href": "architecture.html#data-flow",
    "title": "System Architecture",
    "section": "üîÑ Data Flow",
    "text": "üîÑ Data Flow\n[Dataverse API] ‚Üí [Data Fetch Script] ‚Üí [SQLite DB] ‚Üí [Shiny App UI]\n\n\nDeployment\n\nHosted on: shinyapps.io\nAccess: Public (no login required)\nUpdated automatically every 48 hours\nVersion-controlled via GitHub\n\n\nTip: For details on local development or contributing, see the Developer Guide or Contributing section."
  },
  {
    "objectID": "architecture.html#deployment",
    "href": "architecture.html#deployment",
    "title": "System Architecture",
    "section": "5 Deployment",
    "text": "5 Deployment\n\nHosted on: shinyapps.io\nAccess: Public (no login required)\nUpdated automatically every 48 hours\nVersion-controlled via GitHub\n\n\nTip: For details on local development or contributing, see the Developer Guide or Contributing section."
  },
  {
    "objectID": "architecture.html#key-components-1",
    "href": "architecture.html#key-components-1",
    "title": "System Architecture",
    "section": "2. Key Components",
    "text": "2. Key Components\n\n\n\nComponent\nDescription\n\n\n\n\n2.1 Frontend (User Interface)\nBuilt with R Shiny, the frontend is modular and reactive. It includes:- Carousel-style home summary- Keyword/author network visualization- Data Explorer with filtering- Tooltip and sidebar interactivity- Dynamic filters, value boxes, tables, and visualizations- Hosted on shinyapps.io\n\n\n2.2 Backend (Data Engine)\n- Uses a lightweight SQLite database stored locally- Stores cleaned and structured metadata from the Borealis Dataverse- Includes tables for metadata, files, keywords, authors, and network edges- Optimized for fast queries and minimal setup\n\n\n2.3 API Integration\n- Connects to the Borealis Dataverse API- Retrieves metadata, file listings, DOIs, and keyword-author tags- Data is fetched as JSON and processed into tidy tabular format\n\n\n2.4 Scheduled Update Process\n- Runs every 48 hours to refresh the database- Uses an automated R script to:¬†¬†¬†‚Ä¢ Pull updated metadata and files¬†¬†¬†‚Ä¢ Clean and transform the data¬†¬†¬†‚Ä¢ Merge into the SQLite database- Keeps the app in sync with Borealis\n\n\n\n\nNote: Some of these key features are explained in more detail in the sections that follow."
  },
  {
    "objectID": "api.html",
    "href": "api.html",
    "title": "API Guide",
    "section": "",
    "text": "Below is a summary of the key API endpoints used in RED-X, the type of data each provides, and how it contributes to the app‚Äôs functionality.\n\n\n\n\n\n\n\n\n\nAPI Call Purpose\nEndpoint\nDescription\nInformation Returned\n\n\n\n\nFetch Dataverse Contents\nhttps://borealisdata.ca/api/dataverses/{id}/contents\nRetrieves contents of a given dataverse (datasets and sub-dataverses). Used recursively to explore all levels of the dataverse hierarchy.\nDataset IDs, types (dataset, dataverse), titles, metadata fields\n\n\nFetch Dataverse Metadata\nhttps://borealisdata.ca/api/dataverses/{id}\nRetrieves the name of the dataverse and basic metadata. Used for labeling and organizing datasets by layers (e.g., College, Department).\nDataverse title, alias, description, creation date, and more\n\n\nFetch Dataset Metadata (Study Info)\nhttps://borealisdata.ca/api/datasets/export?exporter=schema.org&persistentId={DOI}\nRetrieves detailed metadata for each dataset using its persistent ID (DOI).\nStudy title, publication date, authors, affiliations, keywords, objectives, data license, spatial and temporal info\n\n\nFetch Dataset Files\nhttps://borealisdata.ca/api/access/dataset/:persistentId/?persistentId={DOI}\nDownloads the zipped data archive for a dataset.\n.tab, .csv, .txt, and other file types packaged in a ZIP archive\n\n\n\n\n1.0 API Token\nTo access the Borealis Dataverse API, RED-X uses a secure API token that is user-specific. This token is stored safely using R‚Äôs system environment variables and never hard coded in the script. This helps protect the token from unauthorized access.\nApi_token <- Sys.getenv(\"API_TOKEN\") # Retrieve the API token from environment variables\n\nThe API token is expected to be stored in your system environment (e.g., .Renviron file). This ensures sensitive credentials are encrypted and hidden from the codebase.\n\nAccess Levels\n\nPublic users (without an API token) can only access openly available datasets.\nAuthenticated users with an API token may access restricted datasets depending on their permissions.\nSuper users (e.g., developers or internal collaborators) may edit the .Renviron file or project settings to include a higher-level API token to unlock more datasets.\n\nIf you are a developer or contributor with elevated access, you can add your token to your environment like so:\n# In .Renviron (do not share publicly!)\nAPI_TOKEN=your-personal-token-here\n\nNever share your API token publicly or hardcode it into your project files.\n\n\n\n2.0 API Calls\nThe RED-X app uses several structured API calls to collect and manage data from the Borealis Dataverse repository. These API integrations enable RED-X to dynamically update its internal SQLite database and render updated network graphs, metadata summaries, and data tables. Below, we outline the core API functions used in the app, the purpose they serve, and the full R implementation.\n\n2.1 Fetch Dataverse Contents\nThis function recursively queries all the nested dataverses and extracts metadata including the title, identifier, and persistent DOI. It builds a tree structure mapping each dataset to its college and department.\nIt returns a tidy tibble with fields such as College_Campus_Institution, Departments_ResearchCentres, and persistent_id, which are later used to fetch detailed metadata and files. See the R code snippet below;\nfetch_all_datasets <- function(id, layer_titles = character()) {\n  base_url <- \"https://borealisdata.ca/api/dataverses/\"\n  results <- tibble()\n\n  if (id == \"147125\") return(results)\n  url <- paste0(base_url, id, \"/contents\")\n  response <- tryCatch({\n    request(url) %>%\n      req_headers(`X-Dataverse-key` = Api_token) %>%\n      req_perform()\n  }, error = function(e) {\n    message(\"Request failed for Dataverse \", id, \": \", e$message)\n    return(NULL)\n  })\n\n  if (!is.null(response) && response$status == 200) {\n    dataverse_raw_data <- fromJSON(rawToChar(response$body), flatten = TRUE) %>%\n      as_tibble()\n    ... \n  }\n}\n\n\n2.2 Fetch Dataverse Metadata\nThis step uses the Borealis endpoint https://borealisdata.ca/api/dataverses/{id} to retrieve basic metadata for a specific dataverse. The goal is to extract the title of each dataverse, which is used in RED-X to label hierarchical layers like College or Department when traversing nested dataverses.\nThe fetch_all_datasets() function calls this endpoint internally while building the dataset tree. If the API returns successfully, the title is appended to a list that represents the current layer of hierarchy.\ntitle <- tryCatch({\n  meta_url <- paste0(base_url, id)\n  meta_response <- request(meta_url) %>%\n    req_headers(`X-Dataverse-key` = Api_token) %>%\n    req_perform()\n\n  meta_data <- fromJSON(rawToChar(meta_response$body), flatten = TRUE)\n  meta_data$data$name\n}, error = function(e) {\n  message(\"Failed to retrieve title for Dataverse \", id, \": \", e$message)\n  return(NA_character_)\n})\nThis snippet is embedded inside the recursive dataset fetching function and helps categorize each dataset by its parent structure. It ensures that the metadata returned from .../dataverses/{id} is used to construct meaningful labels for later use in filtering and network visualization.\n\n\n2.3 Fetch Datasets Metadata\nThis endpoint retrieves rich metadata for a dataset using its persistent identifier (DOI). RED-X uses the Borealis API: https://borealisdata.ca/api/datasets/export?exporter=schema.org&persistentId={DOI} to extract machine-readable metadata structured using schema.org standards.\nFor each DOI collected during the recursive dataverse fetch, this API call returns detailed information such as:\n\nStudy title\nPublication date\nAuthors and affiliations\nKeywords\nObjectives/abstract\nSpatial and temporal coverage\nFunders and license\nList of associated files\n\nThis metadata is compiled into a tidy tibble and cached in the local SQLite database to support search, filtering, visualization, and data exploration across RED-X. The R code for the function can be found below;\n\nfetch_study_details <- function(data) {\n  if (!is.data.frame(data) || !\"persistent_id\" %in% names(data) || nrow(data) == 0) {\n    warning(\"Invalid input: Ensure 'data' is a dataframe and contains 'persistent_id' column.\")\n    return(tibble())\n  }\n\n  BaseURL_details2 <- \"https://borealisdata.ca/api/datasets/export?exporter=schema.org&persistentId=\"\n  detailed_data_list <- vector(\"list\", nrow(data))\n\n  for (i in seq_len(nrow(data))) {\n    persistent_id <- data$persistent_id[i]\n    Full_url_details <- paste0(BaseURL_details2, persistent_id)\n\n    tryCatch({\n      response_details <- request(Full_url_details) %>%\n        req_headers(`X-Dataverse-key` = Api_token) %>%\n        req_perform()\n\n      if (response_details$status == 200) {\n        detail_oac2 <- jsonlite::fromJSON(rawToChar(response_details$body), flatten = TRUE)\n        detailed_data_list[[i]] <- tibble(\n          Title = detail_oac2[[\"name\"]],\n          PublicationDate = detail_oac2[[\"datePublished\"]],\n          Authors = if (!is.null(detail_oac2[[\"author\"]])) paste(detail_oac2[[\"author\"]][[\"name\"]], collapse = \"; \") else NA,\n          Affiliations = if (!is.null(detail_oac2[[\"author\"]][[\"affiliation.name\"]])) paste(detail_oac2[[\"author\"]][[\"affiliation.name\"]], collapse = \"; \") else NA,\n          Keywords = if (!is.null(detail_oac2[[\"keywords\"]])) paste(detail_oac2[[\"keywords\"]], collapse = \"; \") else NA,\n          Objectives = detail_oac2[[\"description\"]],\n          Citation = if (!is.null(detail_oac2[[\"citation\"]])) paste(detail_oac2[[\"citation\"]][[\"name\"]], collapse = \", \") else NA,\n          PeriodCovered = if (!is.null(detail_oac2[[\"temporalCoverage\"]])) paste(detail_oac2[[\"temporalCoverage\"]], collapse = \"; \") else NA,\n          StudyLocation = if (!is.null(detail_oac2[[\"spatialCoverage\"]])) paste(detail_oac2[[\"spatialCoverage\"]], collapse = \", \") else NA,\n          Funder = if (!is.null(detail_oac2[[\"funder\"]])) paste(detail_oac2[[\"funder\"]][[\"name\"]], collapse = \"; \") else NA,\n          FileList = if (!is.null(detail_oac2[[\"distribution\"]])) paste(detail_oac2[[\"distribution\"]][[\"name\"]], collapse = \"; \") else NA,\n          DataLicense = if (!is.null(detail_oac2[[\"license\"]])) paste(detail_oac2[[\"license\"]], collapse = \"; \") else NA,\n          DOI = persistent_id,\n          CollegeName = data$College_Campus_Institution[i],\n          DepartmentName = data$Departments_ResearchCentres[i]\n        )\n      } else {\n        warning(paste(\"Failed to fetch data for DOI:\", persistent_id, \"Status code:\", response_details$status))\n      }\n    }, error = function(e) {\n      message(\"Error fetching details for DOI \", persistent_id, \": \", e$message)\n      detailed_data_list[[i]] <- tibble()\n    })\n  }\n\n  detailed_data <- bind_rows(detailed_data_list) %>% unique()\n  return(detailed_data)\n}\nThis function is essential for enriching the RED-X app with the metadata that powers the keyword/author network, study listings, and search filters.\n\n\n2.4 Fetch Datasets Files\nTo access the raw data files associated with each dataset, RED‚ÄëX uses the following endpoint:\nhttps://borealisdata.ca/api/access/dataset/:persistentId/?persistentId={DOI}\nThis API call downloads a ZIP archive containing all public files linked to a dataset identified by its DOI. These files typically include:\n\n.tab or .csv files (data tables)\n.txt or README files (documentation or metadata)\n\nOther file types (.xls, .zip, images) depending on the study\nThe access_data() function handles the API request, downloads the ZIP content into a temporary directory, extracts the files, and returns a list of file paths. This enables the RED‚ÄëX app to programmatically retrieve and process datasets for filtering, previewing, and metadata display. See the r code below;\naccess_data <- function(doi) {\n  Acess_data_url <- \"https://borealisdata.ca/api/access/dataset/\"\n\n  full_url3 <- paste0(Acess_data_url, \":persistentId/?persistentId=\", doi)\n\n  tryCatch({\n    response <- request(full_url3) %>%\n      req_headers(`X-Dataverse-key`= Api_token) %>%\n      req_perform()\n\n    if (response$status_code == 200) {\n\n      # Get the content of the response as a raw vector\n      zip_content <- resp_body_raw(response)\n\n      # Use tempfile to create a temporary file for the zip content\n      temp_zip <- tempfile(fileext = \".zip\")\n\n      # Write the raw vector to the temporary file\n      writeBin(zip_content, temp_zip)\n\n      # Use a temporary directory to extract the files\n      temp_unzip_dir <- tempfile()\n\n      # Extract the files to the temporary directory\n      unzip(temp_zip, exdir = temp_unzip_dir)\n\n      # List files in the temporary directory\n      file_list <- list.files(temp_unzip_dir, full.names = TRUE)\n\n      # Clean up the temporary zip file\n      unlink(temp_zip)\n\n      return(file_list)\n    }\n    else {\n      return(NULL)\n    }\n\n  }, error = function(e) {\n    print(\"Restricted data not accessible.\")\n  })\n}\nOnly supported file formats are used in the app and are filtered using the function below;\nfilter_filelist(file_list, is_txt = TRUE)  # Get README.txt files\nfilter_filelist(file_list, is_txt = FALSE) # Get .csv/.tab files\n\nSee the Developer Guide to contribute to RED-X."
  },
  {
    "objectID": "dev.html",
    "href": "dev.html",
    "title": "Developer Guide",
    "section": "",
    "text": "2.0 Getting Started\n\n2.1 Prerequisites\nEnsure the following software and system requirements are in place:\n\nR version ‚â• 4.2.0\nRStudio (recommended IDE)\nGit (for cloning the repository)\nInternet access (required for API calls to Borealis)\nQuarto (optional, for building documentation locally)\nrenv package (used to manage project-specific R dependencies)\n\n\nThe RED‚ÄëX app uses renv to isolate and restore R package versions. This ensures that collaborators and users can reproduce the environment consistently across systems.\n\nInstall renv if not already available:\ninstall.packages(\"renv\")\n# Once installed, project dependencies will be restored automatically when you run:\nrenv::restore()\n\n\n2.2 Clone and Set Up the Project\n# Clone the repository\ngit clone https://github.com/agrifooddatacanada/OAC_Historical_Research_Data_Explorer_App.git\n\n# Navigate into the project directory\ncd OAC_Historical_Research_Data_Explorer_App\nOpen the project in RStudio, then run the following in the R console to restore dependencies:\n\n# Restore packages from renv.lock\nrenv::restore()\n\n\n2.3 Running the App Locally\nTo launch the RED-X app from your R console:\n# Run the Shiny app\nshiny::runApp(\"./app\")\nThis will open the app in your default web browser. You may need to wait a few seconds for data to load from the local SQLite database (Explorer_cache.db).\n\n\n\n3.0 API Integration\nRED-X connects to the Borealis Dataverse API to fetch research datasets, metadata, and related files. All API calls are secured using a token stored in your environment variables.\nSys.getenv(\"API_TOKEN\")\n\nNever hardcode your API token in scripts or share it publicly. Access levels may vary depending on your Dataverse role (e.g., contributor, superuser).\n\nKey Functions fetch_all_datasets() ‚Äì Recursively retrieves datasets and structures metadata layers fetch_study_details() ‚Äì Fetches metadata using DOIs access_data() ‚Äì Downloads files associated with each dataset\n\nView detailed API guide here\n\n\n\n4.0 Database and Data Handling\nRED-X uses a local SQLite database (Explorer_cache.db) to store processed research data for fast retrieval and offline access. This approach ensures efficient rendering of network visualizations, metadata tables, and search results, even with large datasets.\n\n4.1 Data Flow\n\n1. Initial Fetch\nOn first run (or every 48 hours), RED-X uses fetch_all_datasets() and fetch_study_details() to pull fresh data via the Dataverse API.\n\n\n2. Transformation & Cleaning\nThe raw metadata is cleaned (e.g., standardizing author/keyword formatting) and structured into consistent formats.\n\n\n3. Storage\nCleaned data is cached in Explorer_cache.db using the DBI and RSQLite packages. This includes:\n\nMain study metadata (research_data)\nNodes and edges for keywords and authors\nUpdate timestamp (update_info)\n\n\n\n4. Automatic Updates\nEvery 48 hours, the system checks for new or modified DOIs and appends only new records‚Äîpreserving performance and avoiding duplication.\n# Check cache timestamp\nif (time_since_last_update > 48 hours) {\n  fetch new DOIs\n  update SQLite cache\n}\n\n\n\n\n5.0 UI and UX Design\nThe RED-X Shiny application offers an intuitive and modular interface designed to support exploratory data analysis and metadata review workflows.\n\n5.1 Layout\nRED-X features a navbar layout, optimized for navigation and accessibility across different data views.\n\nNavbar provides quick access to key tabs\nUI elements are dynamically shown or hidden based on user actions and login status\n\nEach tab supports interactivity, such as dynamic filtering, visualizations, and drill-down views.\n\n\n5.2 Modules\nThe UI is modularized into separate R scripts housed in appTabs/. Each tab is structured as a self-contained Shiny UI component.\nAvailable Tabs:\n\nHome Introduces the app, offers key statistics, and links to explore data.\nNetwork Explorer Interactive visualization of co-occurrence networks for keywords or authors with filtering by college/department.\nData Explorer Displays study-level metadata and allows keyword/DOI search with optional download links for associated files."
  }
]