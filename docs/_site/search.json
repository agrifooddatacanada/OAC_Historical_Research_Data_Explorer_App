[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to RED‚ÄëX",
    "section": "",
    "text": "2.0 Background and Motivation\nRED-X was developed in response to a growing need for efficient access to historical research datasets‚Äîparticularly in the agricultural and environmental sciences.\nOver the years, large volumes of valuable data have been collected by researchers at the University of Guelph, especially through the Ontario Agricultural College (OAC). However, much of this data remained siloed, inconsistently described, or difficult to navigate, making reuse a significant challenge.\nThe motivation behind RED-X came from a workshop hosted by the University of Guelph in collaboration with Compute Ontario, which focused on enhancing the FAIRness (Findability, Accessibility, Interoperability, and Reusability) of research data. Researchers, librarians, and data specialists at the event emphasized the need for a user-friendly tool that could help bridge the gap between stored data and actionable insight.\nRED-X was thus envisioned as a web-based metadata and dataset discovery platform, built using RShiny, that connects directly to Borealis, a Dataverse-based data repository platform. The app provides both technical and non-technical users with intuitive tools for exploring, visualizing, and filtering datasets, enabling better use of existing research outputs and supporting data-driven collaboration across departments and institutions.\n\n\n\n3.0 Purpose & Goals\n\nUnlock historical research insights ‚Äî aggregates metadata and datasets from multiple colleges and departments within the Agri-environmental Research Data dataverse in Borealis (Canadian Dataverse Repository).\nPromote FAIR principles ‚Äî ensures data is Findable, Accessible, Interoperable, and Reusable, elevating the value of Agri-Food data.\nEnhance discoverability ‚Äî presents keyword-author network visualizations and smart filters to reveal connections and trends.\n\n\n\n\n4.0 Who Should Use RED‚ÄëX\n\nAcademic researchers/Scientist investigating historical trends.\n\nData librarians and stewards aiming to manage and share historical datasets.\n\nGraduate students conducting meta-analyses or literature reviews/data review.\n\n\n\n\n5.0 Key Features in Version 2.0\n\nOptimized loading through direct database access and 48‚Äëhour auto-refresh.\n\nNetwork Explorer ‚Äî visualize relationships among keywords, authors, institutions, and colleges.\nExplore datasets and metadata- Navigate historical datasets collected across various colleges and departments, with metadata drawn directly from Borealis.\nSmart Filters ‚Äî quickly navigate by college, department, or campus.\n\nHome Tab Summary ‚Äî at-a-glance metrics for available studies and datasets.\nView study-level summaries - Gain insight into each dataset through high-level summary statistics, research objectives, study location, and associated keywords.\nSeamless navigation ‚Äî one-click access to Network or Data Explorer interfaces.\n\n\n\n\n6.0 Getting Started\nVisit the Getting Started section to learn how to access RED‚ÄëX, review system requirements, and complete your first data query.\n\n\n\n7.0 Browse the Documentation\nUse the sidebar to navigate in sequence:\n\nGetting Started\n\nUser Guide\n\nArchitecture\n\nAPI\nDeveloper Guide\n\n\n\n\n8.0 Support & Credits\nRED‚ÄëX was developed by Agri‚ÄëFood Data Canada at the University of Guelph with support from the Canada First Research Excellence Fund. Special thanks to Dr.¬†Busayo Kodaolu for contributions to the design, development, and documentation of RED‚ÄëX Version 2.0. For inquiries or technical support, contact: adc@uoguelph.ca."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "contributing.html",
    "href": "contributing.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "getting-started.html",
    "href": "getting-started.html",
    "title": "Getting Started",
    "section": "",
    "text": "2.0 Accessing RED-X\nYou can access the app directly through the following link: üîó Launch RED-X\n> Note: No installation or login is required. RED-X is optimized for desktop browsers. Mobile functionality is limited.\n\n\n\n3.0 System Requirements\n\nA modern web browser (Chrome, Firefox, Edge).\nStable internet connection.\nRecommended screen resolution: 1280√ó720 or higher.\n\n\n\n\n4.0 Overview of the Interface\nWhen you launch RED-X, you‚Äôll land on the Home tab, which provides an at-a-glance overview of the database contents. The layout includes a carousel-style summary displaying summary statistics like:\n\nConnected dataverses\nTotal number of studies\nNumber of authors\nAvailable keywords\nNumber of downloadable files\n\n\nIt also introduces users to the two primary interactive tools:\n\n4.1 Network Explorer\nThis tab allows you to explore relationships between keywords, authors, departments, and colleges using an interactive network graph. It‚Äôs designed to support discovery, literature and data review, and collaboration tracking.\n\n\n\n4.2 Data Explorer\nThis section allows users to browse and filter studies, view their metadata, raw data, summary statistic and visualize data. Filters are available by college, campus and institution.\n\n\n\n\n\n5.0 Data Refresh Cycle\nRED-X connects to the Borealis Dataverse using an API. Metadata and datasets are updated every 48 hours to ensure access to the most recent content available from contributing institutions.\n\n\n\n\n6.0 Next Steps\n\nRead the User Guide for more detailed walkthroughs.\nView the Architecture to understand the backend and data flow.\nContact adc@uoguelph.ca for questions or support.\n\n\n\n\n7.0 Want to Contribute?\nIf you‚Äôre interested in the development process or contributing to the project, see the Developer Guide or Contributing section."
  },
  {
    "objectID": "user-guide.html",
    "href": "user-guide.html",
    "title": "User Guide",
    "section": "",
    "text": "2.0 Home Tab\nWhen you first access RED-X, you‚Äôre welcomed by the Home tab, which serves as both an overview and introduction to the platform.\nAt the top of the page is a carousel-style summary that cycles through key statistics and features:\n\nAvailable dataverses\nTotal number of studies\nNumber of authors and keywords\nNumber of downloadable files\n\n\nFigure: Home tab displaying summary statistics.\nThe Home tab also includes a visual preview and description of the two main functional areas of the app:\n\nNetwork Explorer ‚Äì For visualizing data relationships by keyword, author, and institution.\nData Explorer ‚Äì For detailed study-level metadata browsing and file access.\n\nBeneath the carousel, you‚Äôll find a short introduction to the RED-X platform. This text outlines the purpose of the app ‚Äî helping users explore historical Agri-Food data, identify reusable datasets, and support various stages of research.\n\nTip: Use the Home tab as a launching point to understand what‚Äôs available and choose your next step based on your research needs.\n\n\n\n3.0 Network Explorer\nThe Network Explorer tab provides an interactive visualization of how studies are connected through shared keywords and authors, as well as their associated colleges and departments. This tool helps users uncover patterns, identify collaborators, and explore thematic clusters across historical datasets.\nUser can use the filters feature to narrow results, then interact with nodes in the network to see how keywords, people, and institutions are connected.\n\n\n3.1 Featured example:\nSuppose you are planning a research project focused on pH. Here‚Äôs how RED-X supports your workflow:\n\nSearch for the keyword (e.g., ‚ÄúpH‚Äù) to reveal all related studies, other linked keywords, and contributing authors.\n\n\n\nClick nodes to highlight related studies.\nHover over nodes to reveal labels and context.\n\n\n\nUse dropdown filters to focus the network by:\n\nCollege/Campus/Institution\nDepartment/Campus\n\nZoom, pan and scroll down to navigate the network space dynamically and display more details about the keywords including the number of associated studies and links to their DOIs on the Borealis Dataverse.\n\n\nThe visual structure enables discovery of new directions for research, potential collaborators, and dataset relevance based on shared keywords or institutional ties.\n\n\nFigure: Network Explorer showing the keyword ‚ÄúpH‚Äù with connections to related studies, authors, and academic departments.\n\nExplore Collaborations:\nTrace authors or departments with similar work and explore their datasets for deeper context. The legend displays the color assigned to each department, making it easier to visually trace connections within the network. The ‚ÄúShared Across Multiple‚Äù category represents keywords or authors that appear in more than one department or college.\n\n\n\nTip: Use this tool early in your research planning to map out what‚Äôs already been studied and where gaps or opportunities may exist.\n\n\n\n\n4.0 Data Explorer\nThe Data Explorer tab presents a comprehensive, filterable table of all available studies harvested from the Borealis Dataverse. It serves as the primary interface for browsing study-level metadata and accessing associated data files.\nUsers can:\n\nFilter by college, department, or dataverse using dynamic dropdowns.\nSearch by keyword to find studies relevant to specific topics (e.g., pH, manure, cover crops).\n\n\n\nView metadata including study title, publication date, authors, affiliated institution, and study objectives.\n\n\n\nAccess available files.\n\n\n4.1 Featured Example\nThis example walks you through interacting with an individual study using the Data Explorer tab. You can view metadata, inspect raw data files, and review summary statistics to evaluate the study‚Äôs content and reusability.\n\nStudy Overview\n\nThe Study Overview tab provides a concise, table-form summary of the metadata associated with a selected study. It displays key information such as the study title, period covered, DOI, data license, and other relevant details in a clear two-column layout. It also displays some interactive elements such as clickable DOI and license links to enhance usability and visibility. This tab offers users a quick and accessible way to assess study-level information before exploring raw data or associated files.\n\n\nView Metadata\n\nThe Metadata tab helps users explore important background information about each dataset. When available, it shows two sections: a Data Description, which gives general details about the study, and a Data Schema, which outlines the structure of the dataset (such as column names and types). RED-X automatically displays this information if a compatible .txt metadata file is included. However, if no metadata file is found or the file is in an unsupported format (like PDF or Word), the tab will show no metadata file found indicating that metadata is not available. This feature gives users a quick overview of a dataset‚Äôs context before reviewing the raw data.\n\nFigure showing what is displayed when metadata is available\n\n\nFigure showing what is displayed when metadata is not available\n\nData explorer Tab\n\nView All Datafile This section displays the full contents of the selected dataset in an interactive table. Users can scroll, search, and sort the data to explore the raw values directly within the app. It‚Äôs helpful for quickly reviewing the structure of the dataset, spotting missing values, or identifying specific entries.\n\nData Summary The Data Summary section provides basic descriptive statistics for numeric columns in the selected dataset. This includes metrics like mean, minimum, maximum, and counts. It gives users a quick snapshot of the data‚Äôs distribution and quality, helping to assess its potential for reuse. If the dataset contains only text or unsupported values, the summary may be blank or trigger an error message.\n\nNote: The Data Exploration tab only supports .tab or .csv file formats. If no compatible data file is found, or if the dataset is missing entirely, the app will display a message no data files found indicating that no data file is available. Additionally, the Data Summary and Data Visualization features are designed to work with numeric data. If the selected file contains only text or unsupported formats, these sections may show an error or return no results.\n\nData Visualization This section generates simple plots (e.g., histograms or scatter plots) based on the dataset‚Äôs contents. It allows users to visually explore trends, compare variables, and better understand the shape and relationships within the data. Visualizations are most useful when the dataset includes numeric columns. If the data is not suitable for plotting, this section may not display any output.\nSelect studies with accessible files for preliminary data review for reuse. Users can select datasets to view trends and summary statistics, helping them better understand the structure, scope, and potential reusability of historical data for their own research.\n\nFigure: Example of visualizing dataset trends and summary statistics using the data visualization tool within RED-X.\n\nTip: Use the Data Explorer to review metadata and visualize data. Reviewed studies and data can provide useful context or methodological references for prelimimary stage during project development.\n\n\n\n\n5.0 About Tab\nThe About tab contains background information on RED-X, its goals, and contributing institutions. This section is useful for understanding the development context and the broader research infrastructure it supports. It also gives information about the development team.\n\n\n\n6.0 Tips & Best Practices\n\nStart with broad searches to discover unexpected related studies.\nUse both the Network and Data Explorer tabs for a comprehensive view.\nUse the summary boxes in the Home tab to monitor total data availability.\nData updates every 48 hours ‚Äî revisit often for new studies.\n\n\n\n\n7.0 Need More Help?\nIf you need further assistance using the platform, refer to the Getting Started guide or contact the support team at adc@uoguelph.ca."
  },
  {
    "objectID": "user-guide.html#need-more-help",
    "href": "user-guide.html#need-more-help",
    "title": "User Guide",
    "section": "2 Need More Help?",
    "text": "2 Need More Help?\nIf you need further assistance using the platform, refer to the Getting Started guide or contact the support team at adc@uoguelph.ca."
  },
  {
    "objectID": "architecture.html",
    "href": "architecture.html",
    "title": "System Architecture",
    "section": "",
    "text": "2.0 Key components\nRED-X is composed of several key components that work together to deliver a smooth and responsive data exploration experience. Each part plays a specific role in fetching, preparing, and displaying data to users.\n\n\n\nComponent\nDescription\n\n\n\n\nFrontend (User Interface)\nBuilt with R Shiny, the frontend is modular and reactive. It includes:- Carousel-style home summary- Keyword/author network visualization- Data Explorer with filtering- Tooltip and sidebar interactivity- Dynamic filters, value boxes, tables, and visualizations- Hosted on shinyapps.io\n\n\nBackend (Data Engine)\n- Uses a lightweight SQLite database stored locally- Stores cleaned and structured metadata from the Borealis Dataverse- Includes tables for metadata, files, keywords, authors, and network edges- Optimized for fast queries and minimal setup\n\n\nAPI Integration\n- Connects to the Borealis Dataverse API- Retrieves metadata, file listings, DOIs, and keyword-author tags- Data is fetched as JSON and processed into tidy tabular format\n\n\nScheduled Update Process\n- Runs every 48 hours to refresh the database- Uses an automated R script to:¬†¬†¬†‚Ä¢ Pull updated metadata and files¬†¬†¬†‚Ä¢ Clean and transform the data¬†¬†¬†‚Ä¢ Merge into the SQLite database- Keeps the app in sync with Borealis\n\n\n\n\nNote: Some of these key features are explained in more detail in the sections that follow.\n\n\n\n3.0 Data Flow Pipeline\nThe data flow in RED-X follows a streamlined, automated process that ensures users always have access to the most up-to-date study metadata and data files.\nData originates from the Borealis Dataverse, where it is retrieved using API calls. Once fetched, the data is cleaned, transformed, and stored in a local SQLite database, which the app uses to deliver fast and filtered responses to users in real time.The diagram below summarizes the process. Each component plays a specific role in moving data through the system.\n\n\n3.1 Fetching Data from Borealis using API calls\n\n1. API Integration for data fetching\nRED-X connects to the Borealis Dataverse API to fetch metadata, datasets, and file information from public and restricted research repositories. This guide provides a high-level overview of how the API is integrated into the app.\nBelow is a summary of the key API endpoints used in RED-X, the type of data each provides, and how it contributes to the app‚Äôs functionality.\n\n\n\n\n\n\n\n\n\nAPI Call Purpose\nEndpoint\nDescription\nInformation Returned\n\n\n\n\nFetch Dataverse Contents\nhttps://borealisdata.ca/api/dataverses/{id}/contents\nRetrieves contents of a given dataverse (datasets and sub-dataverses). Used recursively to explore all levels of the dataverse hierarchy.\nDataset IDs, types (dataset, dataverse), titles, metadata fields\n\n\nFetch Dataverse Metadata\nhttps://borealisdata.ca/api/dataverses/{id}\nRetrieves the name of the dataverse and basic metadata. Used for labeling and organizing datasets by layers (e.g., College, Department).\nDataverse title, alias, description, creation date, and more\n\n\nFetch Dataset Metadata (Study Info)\nhttps://borealisdata.ca/api/datasets/export?exporter=schema.org&persistentId={DOI}\nRetrieves detailed metadata for each dataset using its persistent ID (DOI).\nStudy title, publication date, authors, affiliations, keywords, objectives, data license, spatial and temporal info\n\n\nFetch Dataset Files\nhttps://borealisdata.ca/api/access/dataset/:persistentId/?persistentId={DOI}\nDownloads the zipped data archive for a dataset.\n.tab, .csv, .txt, and other file types packaged in a ZIP archive\n\n\n\n\nNote: API tokens are user-specific and must be kept secure. In this app, the token is accessed from environment variables using Sys.getenv(\"API_TOKEN\") to avoid hardcoding it in the project. Super users with appropriate permissions can access restricted files. Detailed information about the API integrations and functions can be found at the API Guide section.\n\n\n\n2. Data cleaning, transformation and storage in SQLite database\nAfter data is fetched from the Borealis Dataverse via API calls, it undergoes a structured pipeline that cleans, transforms, and stores the information in a lightweight SQLite database for fast retrieval and application use.\n\nCleaning and Transformation Workflow\n\nThe raw metadata and file listings are parsed and cleaned using a combination of R packages like dplyr, tidyr, and stringr. Below are the main steps:\n\n\n\n\n\n\n\nStep\nDescription\n\n\n\n\nFlatten JSON Responses\nNested JSON responses from the API are converted into tabular format using jsonlite::fromJSON(..., flatten = TRUE).\n\n\nFilter Valid Datasets\nEntries are filtered to ensure they have a valid persistent_id (DOI) and required metadata.\n\n\nExtract and Normalize\nMetadata such as authors, keywords, temporal coverage, and spatial coverage are parsed and stored in a tidy format.\n\n\nString Cleanup\nFields like keywords and authors are cleaned to remove extraneous punctuation, whitespace, or formatting artifacts.\n\n\nDeduplication\nIdentical entries are removed to avoid redundancy using dplyr::distinct().\n\n\nFile Filtering\nOnly .tab, .csv, and metadata .txt files are retained. A helper function filter_filelist() ensures correct file extensions are selected.\n\n\n\n# Example: Clean a raw keyword string\ncleaned_keywords <- str_split(raw_keywords, \";\\\\s*\") %>%\n  unlist() %>%\n  str_replace_all(\"[^a-zA-Z0-9\\\\s-]\", \"\") %>%\n  str_squish() %>%\n  str_to_title() %>%\n  unique()\n\n\n\n3. Storage in SQLite Database\nOnce cleaned, the data is stored in an SQLite database bundled with the Shiny app. This makes querying and updating lightweight, portable, and fast.\n\n\n\n\n\n\n\nTable\nPurpose\n\n\n\n\nresearch_data\nStores the core metadata of all studies (DOI, title, authors, publication date, etc.)\n\n\nupdate_info\nKeeps a timestamp of the last update to prevent redundant API calls (refresh every 48 hours)\n\n\nkeywords_node/edge\nStores the network data for keyword co-occurrence\n\n\nauthors_node/edge\nStores the network data for author collaboration\n\n\ncollege_colors\nColor mapping for each college used in the network visualization\n\n\ndepartment_colors\nColor mapping for each department used in the network visualization\n\n\n\n# Example: Save cleaned study metadata to SQLite\ndbWriteTable(conn, \"research_data\", cleaned_metadata, append = TRUE)\n\nThe SQLite database is accessed by the Shiny app at runtime to populate the user interface with up-to-date and searchable content.\n\n\n\n4. Scheduled Updates\nA background R script checks if an update is needed (based on a 48-hour interval) and refreshes the database only when new datasets are detected. This ensures a responsive app while minimizing API load.\n # Check if update_info table exists and when it was last updated\n  if (\"update_info\" %in% dbListTables(conn)) {\n    update_info <- dbReadTable(conn, \"update_info\")\n    if (nrow(update_info) > 0) {\n      last_update <- as.POSIXct(update_info$last_update[1])\n      time_diff <- difftime(Sys.time(), last_update, units = \"hours\")\n      if (time_diff < 48) {\n        update_needed <- FALSE\n        message(\"Less than 48 hours since last update (\", round(time_diff, 2), \" hours). Using cached data.\")\n      }\n    }\n  }\n  \n  if (!update_needed && (\"research_data\" %in% dbListTables(conn))) {\n    # Return cached data if no update is needed\n    return(dbReadTable(conn, \"research_data\"))\n  }\n  \n  message(\"Updating cache with new data...\")\n\nThis automated pipeline ensures that users always see the most recent research metadata available in the Borealis repository.\n\n\n\n\n\n4.0 Deployment\nThe RED‚ÄëX application is currently deployed using shinyapps.io, a cloud-based hosting service for Shiny applications by RStudio (Posit). This enables the app to be publicly accessible from any browser without requiring local installation of R or its dependencies.\nThe RED-X App is publicly accessible via the following link: Launch RED-X on shinyapps.io\nThis app is actively version-controlled and maintained through GitHub. You can view the full source code, contribute, or report issues using the repository link below: View RED-X on GitHub\nThe GitHub repository contains: - All the source code (UI and server components) - Scripts for API integration and data processing - Deployment and update scripts - Project documentation and development history\n\nTip: For details on local development or contributing, see the Developer Guide section."
  },
  {
    "objectID": "architecture.html#overview",
    "href": "architecture.html#overview",
    "title": "System Architecture",
    "section": "1 Overview",
    "text": "1 Overview\nThe system architecture section provides a high-level overview of how RED-X is built and how its components interact to deliver a seamless user experience. It outlines the core technologies used, the data flow from external sources to the app interface, and how the system stays up-to-date through automated processes.\nThis section is intended for developers, technical reviewers, and advanced users who want to understand how RED-X integrates data from the Borealis Dataverse, processes it for analysis, and presents it through an interactive Shiny interface.\nRED-X is a browser-based web application developed using R Shiny and hosted on shinyapps.io. It connects to a local relational database (SQLite) that is updated every 48 hours via an API integration with the Borealis Dataverse. The system is optimized for metadata visualization, interactive filtering, and reusability analysis."
  },
  {
    "objectID": "architecture.html#system-architecture-diagram",
    "href": "architecture.html#system-architecture-diagram",
    "title": "System Architecture",
    "section": "2 System Architecture Diagram",
    "text": "2 System Architecture Diagram\n\nüì∑ Insert a flow diagram or ERD here\nExample:\n![](images/system-architecture.png){width=80%}"
  },
  {
    "objectID": "architecture.html#key-components",
    "href": "architecture.html#key-components",
    "title": "System Architecture",
    "section": "3 üß© Key Components",
    "text": "3 üß© Key Components\n\n3.1 üîπ Frontend (User Interface)\nBuilt with Shiny, the frontend is modular and reactive. It provides:\n\nCarousel-style home summary\nKeyword/author network visualization\nData Explorer table with filtering\nTooltip and sidebar interactivity\n\n\n\n3.2 üîπ Backend (Data Engine)\n\nSQLite used as the local on-disk relational database\nStores:\n\nStudy metadata\nAuthor/keyword relationships\nNetwork node and edge tables\n\nAll data is auto-refreshed every 48 hours\n\n\n\n3.3 üîπ API Integration\nRED-X uses the Dataverse API to fetch: - Study-level metadata - File listings - Author and keyword tags - DOIs and study-level links\nA scheduled R script (e.g., via cron or shinyapps.io scheduler) handles this process and repopulates the SQLite database."
  },
  {
    "objectID": "architecture.html#data-flow",
    "href": "architecture.html#data-flow",
    "title": "System Architecture",
    "section": "üîÑ Data Flow",
    "text": "üîÑ Data Flow\n[Dataverse API] ‚Üí [Data Fetch Script] ‚Üí [SQLite DB] ‚Üí [Shiny App UI]\n\n\nDeployment\n\nHosted on: shinyapps.io\nAccess: Public (no login required)\nUpdated automatically every 48 hours\nVersion-controlled via GitHub\n\n\nTip: For details on local development or contributing, see the Developer Guide or Contributing section."
  },
  {
    "objectID": "architecture.html#deployment",
    "href": "architecture.html#deployment",
    "title": "System Architecture",
    "section": "5 Deployment",
    "text": "5 Deployment\n\nHosted on: shinyapps.io\nAccess: Public (no login required)\nUpdated automatically every 48 hours\nVersion-controlled via GitHub\n\n\nTip: For details on local development or contributing, see the Developer Guide or Contributing section."
  },
  {
    "objectID": "architecture.html#key-components-1",
    "href": "architecture.html#key-components-1",
    "title": "System Architecture",
    "section": "2. Key Components",
    "text": "2. Key Components\n\n\n\nComponent\nDescription\n\n\n\n\n2.1 Frontend (User Interface)\nBuilt with R Shiny, the frontend is modular and reactive. It includes:- Carousel-style home summary- Keyword/author network visualization- Data Explorer with filtering- Tooltip and sidebar interactivity- Dynamic filters, value boxes, tables, and visualizations- Hosted on shinyapps.io\n\n\n2.2 Backend (Data Engine)\n- Uses a lightweight SQLite database stored locally- Stores cleaned and structured metadata from the Borealis Dataverse- Includes tables for metadata, files, keywords, authors, and network edges- Optimized for fast queries and minimal setup\n\n\n2.3 API Integration\n- Connects to the Borealis Dataverse API- Retrieves metadata, file listings, DOIs, and keyword-author tags- Data is fetched as JSON and processed into tidy tabular format\n\n\n2.4 Scheduled Update Process\n- Runs every 48 hours to refresh the database- Uses an automated R script to:¬†¬†¬†‚Ä¢ Pull updated metadata and files¬†¬†¬†‚Ä¢ Clean and transform the data¬†¬†¬†‚Ä¢ Merge into the SQLite database- Keeps the app in sync with Borealis\n\n\n\n\nNote: Some of these key features are explained in more detail in the sections that follow."
  },
  {
    "objectID": "api.html",
    "href": "api.html",
    "title": "API Guide",
    "section": "",
    "text": "1.0 API Token\nTo access the Borealis Dataverse API, RED-X uses a secure API token that is user-specific. This token is stored safely using R‚Äôs system environment variables and never hard coded in the script. This helps protect the token from unauthorized access.\nApi_token <- Sys.getenv(\"API_TOKEN\") # Retrieve the API token from environment variables\n\nThe API token is expected to be stored in your system environment (e.g., .Renviron file). This ensures sensitive credentials are encrypted and hidden from the codebase.\n\nAccess Levels\n\nPublic users (without an API token) can only access openly available datasets.\nAuthenticated users with an API token may access restricted datasets depending on their permissions.\nSuper users (e.g., developers or internal collaborators) may edit the .Renviron file or project settings to include a higher-level API token to unlock more datasets.\n\nIf you are a developer or contributor with elevated access, you can add your token to your environment like so:\n# In .Renviron (do not share publicly!)\nAPI_TOKEN=your-personal-token-here\n\nNever share your API token publicly or hardcode it into your project files.\n\n\n\n2.0 API Calls\nThe app uses a recursive function to explore dataverses and extract dataset metadata. The first step involves calling the API to recursively retrieve all datasets from all sub-dataverses in the repository:\nfetch_all_datasets <- function(id, layer_titles = character()) {\n  base_url <- \"https://borealisdata.ca/api/dataverses/\"\n  ...\n}\nThis function calls the following endpoint:\nhttps://borealisdata.ca/api/dataverses/{dataverse_id}/contents\nwhich returns a list of datasets and nested dataverses. Each dataset is parsed and assigned metadata such as:\n\nCollege (e.g., Ontario Agricultural College)\nDepartment (e.g., Plant Agriculture)\nPersistent DOI\nHierarchical structure of the repository\n\nEach dataverse is traversed recursively to capture all nested content.\n\n\n3.0 Fetching Metadata and Study Details\nUsing the persistentId of each dataset, metadata is extracted in schema.org format and the following endpoints:\n\"https://borealisdata.ca/api/datasets/export?exporter=schema.org&persistentId={DOI}\"\nThis request returns structured metadata in Schema.org JSON format, including: - Study Title - Publication Date - Authors & affiliations - Keywords - Study Objectives - Spatial & temporal coverage - College and Department Name - Citation Info - Funding source - License & DOI - File Listings\nThe result is parsed and stored as a tibble for downstream processing\n\n\n4.0 Downloading metadata and data Files\nWhen needed, data files are downloaded directly via this endpoint:\nhttps://borealisdata.ca/api/access/dataset/:persistentId/?persistentId={DOI}\nDownloaded ZIP archives are unzipped and filtered for: - .csv or .tab files (raw data) - README.txt files (metadata) Only supported file formats are used in the app and are filtered using the function below;\nfilter_filelist(file_list, is_txt = TRUE)  # Get README.txt files\nfilter_filelist(file_list, is_txt = FALSE) # Get .csv/.tab files"
  },
  {
    "objectID": "dev.html",
    "href": "dev.html",
    "title": "Developer Guide",
    "section": "",
    "text": "2.0 Getting Started\n\n2.1 Prerequisites\nR version >= 4.2\nRStudio (recommended)\nInternet access for API calls\n\n\n2.2 Setup Instructions\ngit clone https://github.com/agrifooddatacanada/OAC_Historical_Research_Data_Explorer_App.git setwd(‚ÄúOAC_Historical_Research_Data_Explorer_App‚Äù) renv::restore()\n\n\n2.3 Running the App\nshiny::runApp(‚Äú./app‚Äù)\n\n\n\n3.0 API Integration\n\n3.1 Overview\nRED-X uses the Borealis Dataverse API to fetch study metadata, authorship, keywords, and files.\n\n\n3.2 API Token\nYour API token is stored in an environment variable:\nSys.getenv(‚ÄúAPI_TOKEN‚Äù)\n‚ö†Ô∏è Never hardcode your API token. Permissions vary by user level.\n\n\n3.3 API Functions\nfetch_all_datasets() ‚Äì Recursively fetches datasets from Dataverse\nfetch_study_details() ‚Äì Pulls metadata using persistent DOIs\naccess_data() ‚Äì Downloads file bundles (ZIP) from Dataverse\n\n\n\n4.0 Database and Data Handling\n\n4.1 Local SQLite Cache\nThe app stores metadata locally for fast loading:\ndbConnect(SQLite(), ‚ÄúExplorer_cache.db‚Äù)\n\n\n4.2 Key Tables\nresearch_data ‚Äì Main table with metadata and links\nupdate_info ‚Äì Tracks last sync time\ncollege_colors / department_colors ‚Äì Categorical color maps\nkeywords_node, keywords_edge ‚Äì Nodes and edges for network graph\n\n\n4.3 Scheduled Updates\nEvery 48 hours:\nAPI is called\nMetadata is refreshed\nCache is merged and updated in SQLite\n\n\n\n5.0 UI and UX Design\n\n5.1 Layout\nNavbar and sidebar-driven interface\nEach tab supports interactivity and filtering\n\n\n5.2 Modules\nTabs include:\nHome\nNetwork Explorer\nData Explorer\nMetadata Viewer\n\n\n\n6.0 Deployment\n\n6.1 Platform\nThe app is hosted publicly on shinyapps.io\n\n\n6.2 Deployment Steps\nLog in to shinyapps.io\nDeploy from RStudio using rsconnect::deployApp()\n\n\n\n7.0 Contributing\n\n7.1 Coding Standards\nFollow tidyverse style\nKeep code modular\nComment your logic\n\n\n7.2 Submitting Changes\nFork and branch\nSubmit PR with description\n\n\n\n8.0 Additional Notes\nDocumentation is generated using Quarto\nVisit the GitHub Repo for full code\nAll diagrams are stored in docs/images/"
  }
]